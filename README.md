---
license: apache-2.0
---

<!-- # Nano-Banana-Figure-LoRA Qwen-Image-Edit Model
This repository provides a LoRA adapters for the Qwen-Image-Edit Model, enabling a high-quality figure image generation.
This LoRAs are trained on manually collected high-quality paired data generated by Nano-Banana. 
 -->

# Nano-Banana Figure-Edit LoRA (Real/Anime/Pet → Figure) for Qwen-Image-Edit

TL;DR. A compact LoRA adapter that specializes Qwen-Image-Edit for a specific editing task: converting real people, anime characters, and pets into figure/collectible (PVC/resin “garage kit”) style images. We curated 100 high-quality paired examples using our Nano-Banana pipeline (powered by Gemini 2.5 Flash – Image Generation), then fine-tuned Qwen-Image-Edit to better preserve identity while applying realistic figure materials, lighting, and product-shot composition.

**Srouce training code: https://github.com/FlyMyAI/flymyai-lora-trainer**


![Comparison](./comparison.png)

Contributor: Song FEI&Tian YE, HKUST Guangzhou.

## Inference Example
```python
import torch
from PIL import Image
from diffusers import DiffusionPipeline
import requests
from io import BytesIO

# Configuration
MODEL_NAME = "/hpc2hdd/home/sfei285/Project/flymyai-lora-trainer/Qwen-Image-Edit"  # Replace with your model
PROMPT = "Use the nano-banana model to create a 1/7 scale commercialized figure of thecharacter in the illustration, in a realistic style and environment. Place the figure on a computer desk, using a circular transparent acrylic base without any text.On the computer screen, display the ZBrush modeling process of the figure. Next to the computer screen, place a BANDAI-style toy packaging box printed with the original artwork."
NEGATIVE_PROMPT = "lowres, bad anatomy, error body, error arm, error hand, error fingers, error leg, error foot, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, jpeg artifacts, ugly, duplicate, morbid, mutilated, out of frame, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry"

# Device setup
device = "cuda"
torch_dtype = torch.bfloat16

print(f"Using device: {device}")

url = "https://huggingface.co/W2GenAI/Nano-Banana-Figure-LoRA/resolve/main/example.jpg"
response = requests.get(url, timeout=30)
input_image = Image.open(BytesIO(response.content)).convert("RGB")
input_image.save("input.jpg")

# Load model
print(f"Loading model: {MODEL_NAME}")
pipe = DiffusionPipeline.from_pretrained(MODEL_NAME, torch_dtype=torch_dtype)

# Load LoRA weights
LORA_WEIGHTS = "W2GenAI/Nano-Banana-Figure-LoRA"
print(f"Loading LoRA weights: {LORA_WEIGHTS}")
pipe.load_lora_weights(LORA_WEIGHTS, adapter_name="lora")

# Move to device
pipe.to(device, dtype=torch_dtype)
pipe.enable_model_cpu_offload()
print("Model ready for inference")

# Generate
generator = torch.Generator(device=device).manual_seed(0)
with torch.inference_mode():
    result = pipe(
        image=input_image,
        prompt=PROMPT,
        negative_prompt=NEGATIVE_PROMPT,
        num_inference_steps=50,
        true_cfg_scale=4.0,
        generator=generator,
    )

# Save result
result.images[0].save("output.jpg")
print("Result saved to output.jpg")
```

